{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T09:09:24.800522Z",
     "start_time": "2020-07-28T09:09:23.278930Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "\n",
    "from sklearn import model_selection, metrics\n",
    "# from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM, Conv1D, MaxPooling1D\n",
    "from tensorflow.python.client import device_lib\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from keras import layers, models\n",
    "#word_tokenizing\n",
    "import re\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# preprocessing\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "# using the Porter Stemmer and Lancaster Stemmer and others\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer,WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk_data.corpora import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-25T11:10:18.132Z"
    }
   },
   "source": [
    "### Text data tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T09:09:38.543630Z",
     "start_time": "2020-07-28T09:09:26.134365Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_data = './Data/tripad_data.csv'\n",
    "raw_data = pd.read_csv(input_data)\n",
    "raw_data = raw_data.dropna(axis=0) # Delete nan rows\n",
    "raw_data = raw_data.drop([\"Unnamed: 0\"], axis=1) # Delete Unnamed: 0 row\n",
    "#print(raw_data['Content'].head)\n",
    "raw_data = raw_data.reset_index()\n",
    "raw_data = raw_data.drop([\"index\"], axis=1)\n",
    "#print(raw_data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T09:11:42.514735Z",
     "start_time": "2020-07-28T09:11:42.512384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HotelInfo.HotelID', 'HotelInfo.Name', 'Author', 'ReviewID', 'Service', 'Cleanliness', 'Rooms', 'Value', 'Sleep Quality', 'Location', 'Business service (e.g., internet access)', 'Check in / front desk', 'Overall', 'Title', 'Content', 'Date', 'AuthorLocation']\n"
     ]
    }
   ],
   "source": [
    "print(list(raw_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T09:11:45.459298Z",
     "start_time": "2020-07-28T09:11:45.449588Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#english (Stopwords file)\n",
    "english_file = open('./Data/english', mode='r')\n",
    "english_data = english_file.readlines()\n",
    "english_text = []\n",
    "\n",
    "for i in english_data:\n",
    "    english_text.append(i[:-1])\n",
    "\n",
    "english_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T09:19:10.400072Z",
     "start_time": "2020-07-28T09:11:50.881596Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          HotelInfo.HotelID       HotelInfo.Name        Author     ReviewID  \\\n",
       "0                   280518  NH Berlin City West       Clara79    UR2592389   \n",
       "1                   280518  NH Berlin City West  BerlinerPooh    UR3015596   \n",
       "2                   280518  NH Berlin City West  amazingthing    UR3456048   \n",
       "3                   280518  NH Berlin City West         Nitus    UR4045777   \n",
       "4                   280518  NH Berlin City West     mattp1874    UR7014779   \n",
       "...                    ...                  ...           ...          ...   \n",
       "1275283              78587          Chablis Inn   tulipslover  UR124992186   \n",
       "1275284              78587          Chablis Inn       Kathi B  UR125442854   \n",
       "1275285              78587          Chablis Inn    Carolynn S  UR125932840   \n",
       "1275286              78587          Chablis Inn    FrankHutch  UR127701764   \n",
       "1275287              78587          Chablis Inn     scoredonu  UR127992624   \n",
       "\n",
       "         Service  Cleanliness  Rooms  Value  Sleep Quality  Location  \\\n",
       "0              3            3      3      4              4         3   \n",
       "1              1            1      0      1              1         1   \n",
       "2              2            4      3      3              4         3   \n",
       "3              4            4      0      5              5         0   \n",
       "4              4            5      4      4              5         5   \n",
       "...          ...          ...    ...    ...            ...       ...   \n",
       "1275283        3            3      3      3              0         0   \n",
       "1275284        4            5      5      4              0         0   \n",
       "1275285        4            5      4      4              0         0   \n",
       "1275286        0            0      0      0              0         0   \n",
       "1275287        2            2      3      3              0         0   \n",
       "\n",
       "         Business service (e.g., internet access)  Check in / front desk  \\\n",
       "0                                               0                      0   \n",
       "1                                               0                      0   \n",
       "2                                               0                      0   \n",
       "3                                               0                      0   \n",
       "4                                               0                      0   \n",
       "...                                           ...                    ...   \n",
       "1275283                                         0                      0   \n",
       "1275284                                         0                      0   \n",
       "1275285                                         0                      0   \n",
       "1275286                                         0                      0   \n",
       "1275287                                         0                      0   \n",
       "\n",
       "         Overall                                   Title  \\\n",
       "0            3.0                       “Loved the Artus”   \n",
       "1            1.0   “A very decent hotel in West Berlin.”   \n",
       "2            3.0                            “Great stay”   \n",
       "3            4.0            “Affordable but very petite”   \n",
       "4            4.0                   “Not quite there yet”   \n",
       "...          ...                                     ...   \n",
       "1275283      3.0                           “Comfortable”   \n",
       "1275284      5.0                   “great value in Napa”   \n",
       "1275285      4.0  “You won't trip over the furniture...”   \n",
       "1275286      4.0   “A clean, welcoming, low-cost option”   \n",
       "1275287      3.0            “Budget Stay in Napa Valley”   \n",
       "\n",
       "                                                   Content  \\\n",
       "0        hotel bit surprise could find review anywhere ...   \n",
       "1        room adequate little drab side noisy main stre...   \n",
       "2        first read review side booking asked quiet dou...   \n",
       "3        one night stay artus hotel berlin hard leave h...   \n",
       "4        stayed hotel night missing finer touch chain t...   \n",
       "...                                                    ...   \n",
       "1275283  hotel cute clean staff nice conveniently locat...   \n",
       "1275284  stay every time napa visiting brother room bar...   \n",
       "1275285  much way furniture room seriously sparse room ...   \n",
       "1275286  surprising alternative many priced accomodatio...   \n",
       "1275287  hotel clearly resort fact motel yes room lot f...   \n",
       "\n",
       "                       Date             AuthorLocation  \n",
       "0        September 22, 2004               Newcastle,UK  \n",
       "1          January 18, 2005             Kigali, Rwanda  \n",
       "2              May 10, 2005                Switzerland  \n",
       "3          October 23, 2005           Willich, Germany  \n",
       "4            March 12, 2007                     London  \n",
       "...                     ...                        ...  \n",
       "1275283   February 21, 2012              San Francisco  \n",
       "1275284       March 1, 2012         North Canton, Ohio  \n",
       "1275285      March 11, 2012  San Francisco, California  \n",
       "1275286      April 11, 2012        Seattle, Washington  \n",
       "1275287      April 16, 2012     Sacramento, California  \n",
       "\n",
       "[1275288 rows x 17 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopwords Removement\n",
    "def clean_review(text):\n",
    "    # 기호문자 제거\n",
    "    review_text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # 소문자로 변경 후 분리\n",
    "    word_tokens = review_text.lower().split()\n",
    "    word_tokens = review_text.lower().split() # 없어도 됨\n",
    "    # 표제어 추출하기 위한 함수\n",
    "    le = WordNetLemmatizer()\n",
    "    # english_text 안의 영어 불용어를 집합으로 변환\n",
    "    stop_words = set(english_text)\n",
    "    word_tokens = [le.lemmatize(w) for w in word_tokens if not w in stop_words]\n",
    "    # 토근화된 문장을 하나의 문장으로 변환\n",
    "    cleaned_review = \" \".join(word_tokens)\n",
    "    \n",
    "    # \\W:비문자 \\b:단어 경계(\\w와 \\W의 경계) \\w:문자\n",
    "    # compile 정규표현식을 컴파일 하는 함수\n",
    "    shortword = re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
    "    cleaned_review = shortword.sub('', cleaned_review)\n",
    "    \n",
    "    return cleaned_review\n",
    "\n",
    "# Stopwords Apply Content 열에 clean_review 함수를 통해 apply\n",
    "raw_data['Content'] = raw_data['Content'].apply(clean_review)\n",
    "raw_data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T09:19:51.889904Z",
     "start_time": "2020-07-28T09:19:17.107680Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# raw_data의 'Content'열의 타입을 str 형태로 변경\n",
    "raw_data['Content'] = raw_data['Content'].astype('str')\n",
    "# raw_data의 'Content'열의 각 문장들을 단어로 tokenize\n",
    "raw_data[\"Content\"] = raw_data[\"Content\"].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T09:19:59.424808Z",
     "start_time": "2020-07-28T09:19:54.752899Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['hotel', 'bit', 'surprise', 'could', 'find', 'review', 'anywhere', 'however', 'turned', 'entirely', 'pleasant', 'one', 'location', 'great', 'close', 'damn', 'charlottenburg', 'literally', 'next', 'berliner', 'strasse', 'bahn', 'staff', 'excellent', 'willing', 'help', 'bunch', 'english', 'direction', 'good', 'restaurant', 'club', 'hour', 'room', 'huge', 'expected', 'bedroom', 'bathroom', 'got', 'luxurious', 'lounge', 'little', 'kitchen', 'would', 'highly', 'recommend', 'hotel', 'anyone', 'paid', 'twin', 'room', 'pity', 'could', 'stay', 'longer', 'appreciate', 'berlin', 'great', 'hotel'])\n",
      " list(['room', 'adequate', 'little', 'drab', 'side', 'noisy', 'main', 'street', 'front', 'kitchenette', 'removed', 'used', 'area', 'storing', 'luggage', 'shopping', 'underground', 'road', 'another', 'across', 'street', 'take', 'time', 'reach', 'fabulous', 'shop', 'restaurant', 'busy', 'area', 'damm', 'main', 'entrance', 'hotel', 'rather', 'grand', 'adjacent', 'large', 'cafeteria', 'bar', 'area', 'breakfast', 'worth', 'getting', 'staff', 'friendly', 'recommended', 'little', 'italian', 'restaurant', 'minute', 'away', 'served', 'best', 'pizza', 'ever', 'needle', 'say', 'went', 'back'])\n",
      " list(['first', 'read', 'review', 'side', 'booking', 'asked', 'quiet', 'double', 'room', 'got', 'one', 'far', 'away', 'main', 'road', 'noise', 'actually', 'little', 'suite', 'bedroom', 'separate', 'living', 'room', 'got', 'kitchenette', 'well', 'per', 'room', 'night', 'compared', 'hotel', 'berlin', 'quite', 'cheap', 'admit', 'hotel', 'bit', 'track', 'step', 'next', 'metro', 'station', 'take', 'stop', 'famous', 'kurf', 'rstendamm', 'railwaystation', 'zoo', 'hotel', 'staff', 'helpful', 'would', 'definetly', 'book', 'next', 'berlin', 'stay', 'hotel'])\n",
      " ...\n",
      " list(['much', 'way', 'furniture', 'room', 'seriously', 'sparse', 'room', 'bed', 'two', 'night', 'stand', 'small', 'desk', 'chair', 'cabinet', 'hold', 'older', 'model', 'around', 'long', 'lettering', 'remote', 'started', 'fade', 'lamp', 'night', 'stand', 'give', 'much', 'light', 'room', 'dark', 'shutter', 'closed', 'must', 'privacy', 'management', 'made', 'attempt', 'update', 'renovate', 'room', 'budget', 'must', 'small', 'thing', 'updated', 'bathroom', 'sink', 'counter', 'door', 'trim', 'throughout', 'chipped', 'peeled', 'stayed', 'groupon', 'deal', 'purchased', 'return'])\n",
      " list(['surprising', 'alternative', 'many', 'priced', 'accomodations', 'napa', 'perfect', 'place', 'family', 'attentive', 'welcoming', 'staff', 'motel', 'surpassed', 'typical', 'motel', 'standard', 'everything', 'nicely', 'painted', 'clean', 'ship', 'shape', 'looking', 'housekeeping', 'staff', 'great', 'job', 'stayed', 'three', 'night', 'many', 'motel', 'would', 'long', 'time', 'chablis', 'inn', 'regret', 'would', 'stay'])\n",
      " list(['hotel', 'clearly', 'resort', 'fact', 'motel', 'yes', 'room', 'lot', 'furniture', 'yes', 'bed', 'best', 'yes', 'hot', 'tub', 'tiny', 'yes', 'hear', 'people', 'moving', 'upper', 'floor', 'yes', 'analog', 'cable', 'however', 'room', 'clean', 'service', 'good', 'location', 'centralized', 'mention', 'budget', 'hotel', 'one', 'suggestion', 'room', 'allow', 'much', 'light', 'room', 'making', 'difficult', 'sleep', 'invest', 'curtain', 'better', 'blind', 'stayed', 'group', 'special', 'translated', 'two', 'night', 'buck', 'rating', 'everything', 'price', 'save', 'money', 'accommodation', 'mean', 'money', 'spend', 'wine', 'tasting', 'eating'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "content_list = np.array(raw_data['Content'].tolist())\n",
    "print(content_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Tokenizing & word_indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T09:21:42.390102Z",
     "start_time": "2020-07-28T09:20:01.665497Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([2, 81, 753, 28, 103, 88, 466, 97, 593, 2810, 277, 9, 14, 3, 64, 4989, 15450, 781, 52, 12302, 9472, 2841, 6, 59, 1076, 272, 2038, 443, 581, 8, 23, 284, 95, 1, 197, 387, 233, 31, 46, 901, 329, 47, 364, 5, 290, 61, 2, 310, 246, 933, 1, 3923, 28, 4, 795, 1579, 1339, 3, 2])\n",
      " list([1, 546, 47, 4179, 150, 386, 204, 60, 44, 1310, 1763, 192, 24, 4099, 335, 223, 1251, 347, 121, 206, 60, 84, 10, 1248, 506, 205, 23, 333, 24, 7154, 204, 570, 2, 393, 314, 1315, 77, 3954, 50, 24, 17, 190, 258, 6, 32, 552, 47, 709, 23, 40, 66, 538, 62, 888, 180, 1225, 101, 72, 30])\n",
      " list([48, 343, 88, 150, 379, 137, 110, 275, 1, 46, 9, 199, 66, 204, 347, 131, 294, 47, 93, 233, 531, 539, 1, 46, 1310, 26, 239, 1, 7, 731, 2, 1339, 99, 357, 1876, 2, 81, 2075, 496, 52, 225, 132, 84, 229, 1585, 13598, 14546, 31202, 1582, 2, 6, 39, 5, 2650, 295, 52, 1339, 4, 2])\n",
      " ...\n",
      " list([45, 68, 569, 1, 1534, 4260, 1, 19, 38, 7, 856, 29, 42, 292, 2474, 1164, 702, 4096, 53, 134, 33157, 1509, 813, 12573, 1414, 7, 856, 263, 45, 304, 1, 543, 3154, 561, 319, 1413, 671, 83, 1973, 2094, 5967, 1, 580, 319, 29, 63, 1006, 31, 481, 978, 65, 6871, 607, 3263, 9733, 13, 7572, 238, 1867, 214])\n",
      " list([2926, 1665, 70, 510, 1722, 1591, 126, 22, 123, 732, 777, 6, 787, 4807, 796, 787, 213, 76, 554, 2448, 16, 1457, 1693, 162, 358, 6, 3, 611, 13, 230, 7, 70, 787, 5, 134, 10, 13047, 346, 1942, 5, 4])\n",
      " list([2, 1096, 55, 382, 787, 373, 1, 56, 569, 373, 19, 62, 373, 151, 306, 444, 373, 338, 54, 1479, 1419, 35, 373, 10815, 947, 97, 1, 16, 18, 8, 14, 8650, 762, 580, 2, 9, 1210, 1, 1445, 45, 304, 1, 437, 809, 226, 5061, 801, 86, 2072, 13, 467, 316, 11555, 38, 7, 1345, 1039, 76, 51, 839, 153, 875, 585, 153, 371, 378, 2131, 721])]\n",
      "(1275288,)\n",
      "[[3 3 4 4 3 3]\n",
      " [1 1 1 1 0 1]\n",
      " [2 4 3 4 3 3]\n",
      " ...\n",
      " [4 5 4 0 4 0]\n",
      " [0 0 0 0 0 0]\n",
      " [2 2 3 0 3 0]]\n",
      "(1275288, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(content_list)\n",
    "\n",
    "ipc_Xdata = np.array(tokenizer.texts_to_sequences(content_list))\n",
    "\n",
    "print(ipc_Xdata)\n",
    "print(ipc_Xdata.shape)\n",
    "\n",
    "ipc_Ydata = np.array(raw_data[['Service', 'Cleanliness','Value',\n",
    "                               'Sleep Quality','Rooms','Location']])\n",
    "print(ipc_Ydata)\n",
    "print(ipc_Ydata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split & Get maxlen and max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T09:22:19.175186Z",
     "start_time": "2020-07-28T09:22:18.844873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(892701,) (382587,) (892701, 6) (382587, 6)\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(ipc_Xdata, ipc_Ydata, \n",
    "                                                    test_size=0.3)\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T09:22:33.968030Z",
     "start_time": "2020-07-28T09:22:21.012395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2654\n",
      "263169\n"
     ]
    }
   ],
   "source": [
    "# 최대 길이 및 최대 feature 값 구하기\n",
    "maxlen = 1\n",
    "max_features = 1\n",
    "for idx in ipc_Xdata :\n",
    "    try :\n",
    "        len_ = len(idx) #print(idx)\n",
    "        max_ = np.max(idx)\n",
    "    except :\n",
    "        #print(idx)\n",
    "        continue\n",
    "    #print(type(max_))\n",
    "    #break\n",
    "    if max_features < max_ :\n",
    "        max_features = max_\n",
    "    if maxlen < len_ :\n",
    "        maxlen = len_\n",
    "print(maxlen)\n",
    "print(max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T05:51:33.419252Z",
     "start_time": "2020-07-24T05:51:33.381734Z"
    }
   },
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T09:22:49.386363Z",
     "start_time": "2020-07-28T09:22:38.125720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "892701 train sequences\n",
      "382587 test sequences\n",
      "(892701,) (382587,) (892701, 6) (382587, 6)\n",
      "Pad sequences (samples x time)\n",
      "train_x shape: (892701, 2654)\n",
      "test_x shape: (382587, 2654)\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "\n",
    "print(len(train_x), 'train sequences')\n",
    "print(len(test_x), 'test sequences')\n",
    "\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "\n",
    "train_x = sequence.pad_sequences(train_x, maxlen=maxlen)\n",
    "test_x = sequence.pad_sequences(test_x, maxlen=maxlen)\n",
    "print('train_x shape:', train_x.shape)\n",
    "print('test_x shape:', test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### variables setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T10:44:05.879398Z",
     "start_time": "2020-07-28T10:44:05.876297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Embedding\n",
    "max_features = max_features+1 # feature 값 변경\n",
    "# maxlen = 2670 # 리뷰의 길이\n",
    "embedding_size = 128\n",
    "\n",
    "# Convolution\n",
    "kernel_size = 5 # 1\n",
    "filters = 256 # 256\n",
    "pool_size = 4\n",
    "\n",
    "# LSTM\n",
    "lstm_output_size = 10\n",
    "\n",
    "# Training\n",
    "batch_size = 1000 # 310 #30 -> 20\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T10:44:11.886017Z",
     "start_time": "2020-07-28T10:44:11.603887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 2654)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 2654, 512)    134744064   input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 2650, 256)    655616      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 662, 256)     0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 659, 128)     131200      max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 164, 128)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 162, 64)      24640       max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 40, 64)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 40, 64)       25088       max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 40, 64)       0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2560)         0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            2561        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            2561        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            2561        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            2561        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            2561        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            2561        flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 135,595,974\n",
      "Trainable params: 135,595,974\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "#model = Sequential()\n",
    "input_layer = layers.Input((maxlen,))\n",
    "\n",
    "embedding_layer = layers.Embedding(max_features, 512)(input_layer)\n",
    "\n",
    "convolution_layer = layers.Conv1D(256, 5, padding = 'valid',\n",
    "                                 activation='relu', strides=1)(embedding_layer)\n",
    "maxpooling_layer = layers.MaxPooling1D(pool_size)(convolution_layer)\n",
    "\n",
    "convolution_layer2 = layers.Conv1D(128, 4, padding = 'valid',\n",
    "                                 activation='relu', strides=1)(maxpooling_layer)\n",
    "maxpooling_layer2 = layers.MaxPooling1D(pool_size)(convolution_layer2)\n",
    "\n",
    "convolution_layer3 = layers.Conv1D(64, 3, padding = 'valid',\n",
    "                                 activation='relu', strides=1)(maxpooling_layer2)\n",
    "maxpooling_layer3 = layers.MaxPooling1D(pool_size)(convolution_layer3)\n",
    "\n",
    "lstm_layer = layers.Bidirectional(layers.CuDNNLSTM(32,return_sequences=True))(maxpooling_layer3)\n",
    "\n",
    "#lstm_layer = layers.CuDNNLSTM(64,return_sequences=True)(maxpooling_layer3)\n",
    "\n",
    "dropout_layer = layers.Dropout(0.25)(lstm_layer) \n",
    "\n",
    "flatten_layer = layers.Flatten()(dropout_layer)\n",
    "\n",
    "output_layer1 = layers.Dense(1, activation = 'sigmoid')(flatten_layer)\n",
    "output_layer2 = layers.Dense(1, activation = 'sigmoid')(flatten_layer)\n",
    "output_layer3 = layers.Dense(1, activation = 'sigmoid')(flatten_layer)\n",
    "output_layer4 = layers.Dense(1, activation = 'sigmoid')(flatten_layer)\n",
    "output_layer5 = layers.Dense(1, activation = 'sigmoid')(flatten_layer)\n",
    "output_layer6 = layers.Dense(1, activation = 'sigmoid')(flatten_layer)\n",
    "\n",
    "model = models.Model(inputs=input_layer, outputs=\n",
    "                     [output_layer1, output_layer2, output_layer3, output_layer4,\n",
    "                      output_layer5, output_layer6])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mse', optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T11:02:14.429633Z",
     "start_time": "2020-07-28T10:44:15.587397Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 134744064 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "892701/892701 [==============================] - 839s 940us/step - loss: 0.7988 - dense_13_loss: 0.1077 - dense_14_loss: 0.1028 - dense_15_loss: 0.1046 - dense_16_loss: 0.1899 - dense_17_loss: 0.1333 - dense_18_loss: 0.1605 - dense_13_acc: 0.4387 - dense_14_acc: 0.4920 - dense_15_acc: 0.3715 - dense_16_acc: 0.5032 - dense_17_acc: 0.3223 - dense_18_acc: 0.4540\n",
      "382587/382587 [==============================] - 105s 273us/step\n",
      "predicted :  [array([[0.85695136],\n",
      "       [0.8204434 ],\n",
      "       [0.84159935],\n",
      "       ...,\n",
      "       [0.7392229 ],\n",
      "       [0.71203214],\n",
      "       [0.7392229 ]], dtype=float32), array([[0.8826119 ],\n",
      "       [0.84971035],\n",
      "       [0.8687531 ],\n",
      "       ...,\n",
      "       [0.776917  ],\n",
      "       [0.751029  ],\n",
      "       [0.776917  ]], dtype=float32), array([[0.8146444 ],\n",
      "       [0.7830022 ],\n",
      "       [0.8022162 ],\n",
      "       ...,\n",
      "       [0.72077453],\n",
      "       [0.6993087 ],\n",
      "       [0.72077453]], dtype=float32), array([[0.5697071 ],\n",
      "       [0.5019787 ],\n",
      "       [0.5091928 ],\n",
      "       ...,\n",
      "       [0.36268762],\n",
      "       [0.3586141 ],\n",
      "       [0.36268762]], dtype=float32), array([[0.76600957],\n",
      "       [0.7247884 ],\n",
      "       [0.7576225 ],\n",
      "       ...,\n",
      "       [0.657441  ],\n",
      "       [0.625322  ],\n",
      "       [0.657441  ]], dtype=float32), array([[0.79104954],\n",
      "       [0.75759864],\n",
      "       [0.7819639 ],\n",
      "       ...,\n",
      "       [0.69370073],\n",
      "       [0.6668529 ],\n",
      "       [0.69370073]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with K.tf.device('/gpu:0'):\n",
    "    print('Train...')\n",
    "    hist = model.fit(train_x, [train_y[:,0]/5, train_y[:,1]/5, \n",
    "                               train_y[:,2]/5, train_y[:,3]/5, \n",
    "                               train_y[:,4]/5, train_y[:,5]/5],\n",
    "                     batch_size=batch_size,\n",
    "                     epochs=epochs)\n",
    "    \n",
    "   # score, acc = model.evaluate(test_x, test_y[:,0:6], \n",
    "   #                             batch_size=batch_size)\n",
    "    \n",
    "    score = model.evaluate(test_x, [test_y[:,0]/5, test_y[:,1]/5,\n",
    "                                     test_y[:,2]/5, test_y[:,3]/5,\n",
    "                                     test_y[:,4]/5, test_y[:,5]/5], \n",
    "                            batch_size = batch_size)\n",
    "    \n",
    "    predicted = model.predict(test_x)\n",
    "    print('predicted : ',predicted)\n",
    "    #print('Test score:', score)\n",
    "    #print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T11:06:48.859771Z",
     "start_time": "2020-07-28T11:06:48.848262Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382587\n",
      "6\n",
      "(6, 382587, 1)\n",
      "[[[0.85695136]\n",
      "  [0.8204434 ]\n",
      "  [0.84159935]\n",
      "  ...\n",
      "  [0.7392229 ]\n",
      "  [0.71203214]\n",
      "  [0.7392229 ]]\n",
      "\n",
      " [[0.8826119 ]\n",
      "  [0.84971035]\n",
      "  [0.8687531 ]\n",
      "  ...\n",
      "  [0.776917  ]\n",
      "  [0.751029  ]\n",
      "  [0.776917  ]]\n",
      "\n",
      " [[0.8146444 ]\n",
      "  [0.7830022 ]\n",
      "  [0.8022162 ]\n",
      "  ...\n",
      "  [0.72077453]\n",
      "  [0.6993087 ]\n",
      "  [0.72077453]]\n",
      "\n",
      " [[0.5697071 ]\n",
      "  [0.5019787 ]\n",
      "  [0.5091928 ]\n",
      "  ...\n",
      "  [0.36268762]\n",
      "  [0.3586141 ]\n",
      "  [0.36268762]]\n",
      "\n",
      " [[0.76600957]\n",
      "  [0.7247884 ]\n",
      "  [0.7576225 ]\n",
      "  ...\n",
      "  [0.657441  ]\n",
      "  [0.625322  ]\n",
      "  [0.657441  ]]\n",
      "\n",
      " [[0.79104954]\n",
      "  [0.75759864]\n",
      "  [0.7819639 ]\n",
      "  ...\n",
      "  [0.69370073]\n",
      "  [0.6668529 ]\n",
      "  [0.69370073]]]\n",
      "(382587, 6)\n",
      "times 5\n",
      "(382587, 6)\n",
      "[[4 4 4 2 3 3]\n",
      " [4 4 3 2 3 3]\n",
      " [4 4 4 2 3 3]\n",
      " ...\n",
      " [3 3 3 1 3 3]\n",
      " [3 3 3 1 3 3]\n",
      " [3 3 3 1 3 3]]\n"
     ]
    }
   ],
   "source": [
    "print(len(test_x))\n",
    "print(len(predicted))\n",
    "arr_predicted = np.array(predicted)\n",
    "print(arr_predicted.shape)\n",
    "print(arr_predicted)\n",
    "\n",
    "arr = np.squeeze(arr_predicted, 2)\n",
    "arr = np.transpose(arr)\n",
    "print(arr.shape)\n",
    "print('times 5')\n",
    "# print(arr)\n",
    "arr = arr * 5\n",
    "# arr = np.rint(arr)\n",
    "arr = arr.astype('int64')\n",
    "print(arr.shape)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T11:06:51.474884Z",
     "start_time": "2020-07-28T11:06:51.472217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 4 4 5 0 0]\n",
      " [5 5 5 5 5 5]\n",
      " [4 5 4 5 4 5]\n",
      " [4 3 5 0 4 5]]\n",
      "[[4 4 4 2 3 3]\n",
      " [4 4 3 2 3 3]\n",
      " [4 4 4 2 3 3]\n",
      " [3 3 3 1 3 3]]\n"
     ]
    }
   ],
   "source": [
    "print(test_y[:4])\n",
    "print(arr[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning process graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T10:42:17.068536Z",
     "start_time": "2020-07-28T10:42:16.905157Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b8ac582d4f01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss_ax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0macc_ax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mloss_ax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "367.390625px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1525px",
    "right": "20px",
    "top": "152px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
