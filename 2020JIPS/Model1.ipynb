{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T19:15:14.528478Z",
     "start_time": "2020-07-26T19:15:14.522212Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "\n",
    "from sklearn import model_selection, metrics\n",
    "# from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM, Conv1D, MaxPooling1D\n",
    "from tensorflow.python.client import device_lib\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from keras import layers, models\n",
    "#word_tokenizing\n",
    "import re\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# preprocessing\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "# using the Porter Stemmer and Lancaster Stemmer and others\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer,WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk_data.corpora import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-25T11:10:18.132Z"
    }
   },
   "source": [
    "### Text data tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T19:15:29.006679Z",
     "start_time": "2020-07-26T19:15:17.700277Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_data = './Data/tripad_data.csv'\n",
    "raw_data = pd.read_csv(input_data)\n",
    "raw_data = raw_data.dropna(axis=0) # Delete nan rows\n",
    "raw_data = raw_data.drop([\"Unnamed: 0\"], axis=1) # Delete Unnamed: 0 row\n",
    "#print(raw_data['Content'].head)\n",
    "raw_data = raw_data.reset_index()\n",
    "raw_data = raw_data.drop([\"index\"], axis=1)\n",
    "#print(raw_data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T19:15:29.112801Z",
     "start_time": "2020-07-26T19:15:29.110517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HotelInfo.HotelID', 'HotelInfo.Name', 'Author', 'ReviewID', 'Service', 'Cleanliness', 'Rooms', 'Value', 'Sleep Quality', 'Location', 'Business service (e.g., internet access)', 'Check in / front desk', 'Overall', 'Title', 'Content', 'Date', 'AuthorLocation']\n"
     ]
    }
   ],
   "source": [
    "print(list(raw_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T19:15:29.216476Z",
     "start_time": "2020-07-26T19:15:29.210054Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#english (Stopwords file)\n",
    "english_file = open('./Data/english', mode='r')\n",
    "english_data = english_file.readlines()\n",
    "english_text = []\n",
    "\n",
    "for i in english_data:\n",
    "    english_text.append(i[:-1])\n",
    "\n",
    "english_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T19:22:19.290943Z",
     "start_time": "2020-07-26T19:15:29.332247Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          HotelInfo.HotelID       HotelInfo.Name        Author     ReviewID  \\\n",
       "0                   280518  NH Berlin City West       Clara79    UR2592389   \n",
       "1                   280518  NH Berlin City West  BerlinerPooh    UR3015596   \n",
       "2                   280518  NH Berlin City West  amazingthing    UR3456048   \n",
       "3                   280518  NH Berlin City West         Nitus    UR4045777   \n",
       "4                   280518  NH Berlin City West     mattp1874    UR7014779   \n",
       "...                    ...                  ...           ...          ...   \n",
       "1275283              78587          Chablis Inn   tulipslover  UR124992186   \n",
       "1275284              78587          Chablis Inn       Kathi B  UR125442854   \n",
       "1275285              78587          Chablis Inn    Carolynn S  UR125932840   \n",
       "1275286              78587          Chablis Inn    FrankHutch  UR127701764   \n",
       "1275287              78587          Chablis Inn     scoredonu  UR127992624   \n",
       "\n",
       "         Service  Cleanliness  Rooms  Value  Sleep Quality  Location  \\\n",
       "0              3            3      3      4              4         3   \n",
       "1              1            1      0      1              1         1   \n",
       "2              2            4      3      3              4         3   \n",
       "3              4            4      0      5              5         0   \n",
       "4              4            5      4      4              5         5   \n",
       "...          ...          ...    ...    ...            ...       ...   \n",
       "1275283        3            3      3      3              0         0   \n",
       "1275284        4            5      5      4              0         0   \n",
       "1275285        4            5      4      4              0         0   \n",
       "1275286        0            0      0      0              0         0   \n",
       "1275287        2            2      3      3              0         0   \n",
       "\n",
       "         Business service (e.g., internet access)  Check in / front desk  \\\n",
       "0                                               0                      0   \n",
       "1                                               0                      0   \n",
       "2                                               0                      0   \n",
       "3                                               0                      0   \n",
       "4                                               0                      0   \n",
       "...                                           ...                    ...   \n",
       "1275283                                         0                      0   \n",
       "1275284                                         0                      0   \n",
       "1275285                                         0                      0   \n",
       "1275286                                         0                      0   \n",
       "1275287                                         0                      0   \n",
       "\n",
       "         Overall                                   Title  \\\n",
       "0            3.0                       “Loved the Artus”   \n",
       "1            1.0   “A very decent hotel in West Berlin.”   \n",
       "2            3.0                            “Great stay”   \n",
       "3            4.0            “Affordable but very petite”   \n",
       "4            4.0                   “Not quite there yet”   \n",
       "...          ...                                     ...   \n",
       "1275283      3.0                           “Comfortable”   \n",
       "1275284      5.0                   “great value in Napa”   \n",
       "1275285      4.0  “You won't trip over the furniture...”   \n",
       "1275286      4.0   “A clean, welcoming, low-cost option”   \n",
       "1275287      3.0            “Budget Stay in Napa Valley”   \n",
       "\n",
       "                                                   Content  \\\n",
       "0        hotel bit surprise could find review anywhere ...   \n",
       "1        room adequate little drab side noisy main stre...   \n",
       "2        first read review side booking asked quiet dou...   \n",
       "3        one night stay artus hotel berlin hard leave h...   \n",
       "4        stayed hotel night missing finer touch chain t...   \n",
       "...                                                    ...   \n",
       "1275283  hotel cute clean staff nice conveniently locat...   \n",
       "1275284  stay every time napa visiting brother room bar...   \n",
       "1275285  much way furniture room seriously sparse room ...   \n",
       "1275286  surprising alternative many priced accomodatio...   \n",
       "1275287  hotel clearly resort fact motel yes room lot f...   \n",
       "\n",
       "                       Date             AuthorLocation  \n",
       "0        September 22, 2004               Newcastle,UK  \n",
       "1          January 18, 2005             Kigali, Rwanda  \n",
       "2              May 10, 2005                Switzerland  \n",
       "3          October 23, 2005           Willich, Germany  \n",
       "4            March 12, 2007                     London  \n",
       "...                     ...                        ...  \n",
       "1275283   February 21, 2012              San Francisco  \n",
       "1275284       March 1, 2012         North Canton, Ohio  \n",
       "1275285      March 11, 2012  San Francisco, California  \n",
       "1275286      April 11, 2012        Seattle, Washington  \n",
       "1275287      April 16, 2012     Sacramento, California  \n",
       "\n",
       "[1275288 rows x 17 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopwords Removement\n",
    "def clean_review(text):\n",
    "    # 기호문자 제거\n",
    "    review_text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # 소문자로 변경 후 분리\n",
    "    word_tokens = review_text.lower().split()\n",
    "    word_tokens = review_text.lower().split() # 없어도 됨\n",
    "    # 표제어 추출하기 위한 함수\n",
    "    le = WordNetLemmatizer()\n",
    "    # english_text 안의 영어 불용어를 집합으로 변환\n",
    "    stop_words = set(english_text)\n",
    "    word_tokens = [le.lemmatize(w) for w in word_tokens if not w in stop_words]\n",
    "    # 토근화된 문장을 하나의 문장으로 변환\n",
    "    cleaned_review = \" \".join(word_tokens)\n",
    "    \n",
    "    # \\W:비문자 \\b:단어 경계(\\w와 \\W의 경계) \\w:문자\n",
    "    # compile 정규표현식을 컴파일 하는 함수\n",
    "    shortword = re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
    "    cleaned_review = shortword.sub('', cleaned_review)\n",
    "    \n",
    "    return cleaned_review\n",
    "\n",
    "# Stopwords Apply Content 열에 clean_review 함수를 통해 apply\n",
    "raw_data['Content'] = raw_data['Content'].apply(clean_review)\n",
    "raw_data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T19:22:42.978816Z",
     "start_time": "2020-07-26T19:22:19.397142Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# raw_data의 'Content'열의 타입을 str 형태로 변경\n",
    "raw_data['Content'] = raw_data['Content'].astype('str')\n",
    "# raw_data의 'Content'열의 각 문장들을 단어로 tokenize\n",
    "raw_data[\"Content\"] = raw_data[\"Content\"].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T19:22:47.083714Z",
     "start_time": "2020-07-26T19:22:43.099500Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['hotel', 'bit', 'surprise', 'could', 'find', 'review', 'anywhere', 'however', 'turned', 'entirely', 'pleasant', 'one', 'location', 'great', 'close', 'damn', 'charlottenburg', 'literally', 'next', 'berliner', 'strasse', 'bahn', 'staff', 'excellent', 'willing', 'help', 'bunch', 'english', 'direction', 'good', 'restaurant', 'club', 'hour', 'room', 'huge', 'expected', 'bedroom', 'bathroom', 'got', 'luxurious', 'lounge', 'little', 'kitchen', 'would', 'highly', 'recommend', 'hotel', 'anyone', 'paid', 'twin', 'room', 'pity', 'could', 'stay', 'longer', 'appreciate', 'berlin', 'great', 'hotel'])\n",
      " list(['room', 'adequate', 'little', 'drab', 'side', 'noisy', 'main', 'street', 'front', 'kitchenette', 'removed', 'used', 'area', 'storing', 'luggage', 'shopping', 'underground', 'road', 'another', 'across', 'street', 'take', 'time', 'reach', 'fabulous', 'shop', 'restaurant', 'busy', 'area', 'damm', 'main', 'entrance', 'hotel', 'rather', 'grand', 'adjacent', 'large', 'cafeteria', 'bar', 'area', 'breakfast', 'worth', 'getting', 'staff', 'friendly', 'recommended', 'little', 'italian', 'restaurant', 'minute', 'away', 'served', 'best', 'pizza', 'ever', 'needle', 'say', 'went', 'back'])\n",
      " list(['first', 'read', 'review', 'side', 'booking', 'asked', 'quiet', 'double', 'room', 'got', 'one', 'far', 'away', 'main', 'road', 'noise', 'actually', 'little', 'suite', 'bedroom', 'separate', 'living', 'room', 'got', 'kitchenette', 'well', 'per', 'room', 'night', 'compared', 'hotel', 'berlin', 'quite', 'cheap', 'admit', 'hotel', 'bit', 'track', 'step', 'next', 'metro', 'station', 'take', 'stop', 'famous', 'kurf', 'rstendamm', 'railwaystation', 'zoo', 'hotel', 'staff', 'helpful', 'would', 'definetly', 'book', 'next', 'berlin', 'stay', 'hotel'])\n",
      " ...\n",
      " list(['much', 'way', 'furniture', 'room', 'seriously', 'sparse', 'room', 'bed', 'two', 'night', 'stand', 'small', 'desk', 'chair', 'cabinet', 'hold', 'older', 'model', 'around', 'long', 'lettering', 'remote', 'started', 'fade', 'lamp', 'night', 'stand', 'give', 'much', 'light', 'room', 'dark', 'shutter', 'closed', 'must', 'privacy', 'management', 'made', 'attempt', 'update', 'renovate', 'room', 'budget', 'must', 'small', 'thing', 'updated', 'bathroom', 'sink', 'counter', 'door', 'trim', 'throughout', 'chipped', 'peeled', 'stayed', 'groupon', 'deal', 'purchased', 'return'])\n",
      " list(['surprising', 'alternative', 'many', 'priced', 'accomodations', 'napa', 'perfect', 'place', 'family', 'attentive', 'welcoming', 'staff', 'motel', 'surpassed', 'typical', 'motel', 'standard', 'everything', 'nicely', 'painted', 'clean', 'ship', 'shape', 'looking', 'housekeeping', 'staff', 'great', 'job', 'stayed', 'three', 'night', 'many', 'motel', 'would', 'long', 'time', 'chablis', 'inn', 'regret', 'would', 'stay'])\n",
      " list(['hotel', 'clearly', 'resort', 'fact', 'motel', 'yes', 'room', 'lot', 'furniture', 'yes', 'bed', 'best', 'yes', 'hot', 'tub', 'tiny', 'yes', 'hear', 'people', 'moving', 'upper', 'floor', 'yes', 'analog', 'cable', 'however', 'room', 'clean', 'service', 'good', 'location', 'centralized', 'mention', 'budget', 'hotel', 'one', 'suggestion', 'room', 'allow', 'much', 'light', 'room', 'making', 'difficult', 'sleep', 'invest', 'curtain', 'better', 'blind', 'stayed', 'group', 'special', 'translated', 'two', 'night', 'buck', 'rating', 'everything', 'price', 'save', 'money', 'accommodation', 'mean', 'money', 'spend', 'wine', 'tasting', 'eating'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "content_list = np.array(raw_data['Content'].tolist())\n",
    "print(content_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Tokenizing & word_indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T19:24:19.538025Z",
     "start_time": "2020-07-26T19:22:47.209888Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([2, 81, 753, 28, 103, 88, 466, 97, 593, 2810, 277, 9, 14, 3, 64, 4989, 15450, 781, 52, 12302, 9472, 2841, 6, 59, 1076, 272, 2038, 443, 581, 8, 23, 284, 95, 1, 197, 387, 233, 31, 46, 901, 329, 47, 364, 5, 290, 61, 2, 310, 246, 933, 1, 3923, 28, 4, 795, 1579, 1339, 3, 2])\n",
      " list([1, 546, 47, 4179, 150, 386, 204, 60, 44, 1310, 1763, 192, 24, 4099, 335, 223, 1251, 347, 121, 206, 60, 84, 10, 1248, 506, 205, 23, 333, 24, 7154, 204, 570, 2, 393, 314, 1315, 77, 3954, 50, 24, 17, 190, 258, 6, 32, 552, 47, 709, 23, 40, 66, 538, 62, 888, 180, 1225, 101, 72, 30])\n",
      " list([48, 343, 88, 150, 379, 137, 110, 275, 1, 46, 9, 199, 66, 204, 347, 131, 294, 47, 93, 233, 531, 539, 1, 46, 1310, 26, 239, 1, 7, 731, 2, 1339, 99, 357, 1876, 2, 81, 2075, 496, 52, 225, 132, 84, 229, 1585, 13598, 14546, 31202, 1582, 2, 6, 39, 5, 2650, 295, 52, 1339, 4, 2])\n",
      " ...\n",
      " list([45, 68, 569, 1, 1534, 4260, 1, 19, 38, 7, 856, 29, 42, 292, 2474, 1164, 702, 4096, 53, 134, 33157, 1509, 813, 12573, 1414, 7, 856, 263, 45, 304, 1, 543, 3154, 561, 319, 1413, 671, 83, 1973, 2094, 5967, 1, 580, 319, 29, 63, 1006, 31, 481, 978, 65, 6871, 607, 3263, 9733, 13, 7572, 238, 1867, 214])\n",
      " list([2926, 1665, 70, 510, 1722, 1591, 126, 22, 123, 732, 777, 6, 787, 4807, 796, 787, 213, 76, 554, 2448, 16, 1457, 1693, 162, 358, 6, 3, 611, 13, 230, 7, 70, 787, 5, 134, 10, 13047, 346, 1942, 5, 4])\n",
      " list([2, 1096, 55, 382, 787, 373, 1, 56, 569, 373, 19, 62, 373, 151, 306, 444, 373, 338, 54, 1479, 1419, 35, 373, 10815, 947, 97, 1, 16, 18, 8, 14, 8650, 762, 580, 2, 9, 1210, 1, 1445, 45, 304, 1, 437, 809, 226, 5061, 801, 86, 2072, 13, 467, 316, 11555, 38, 7, 1345, 1039, 76, 51, 839, 153, 875, 585, 153, 371, 378, 2131, 721])]\n",
      "(1275288,)\n",
      "[[3 3 4 4 3 3]\n",
      " [1 1 1 1 0 1]\n",
      " [2 4 3 4 3 3]\n",
      " ...\n",
      " [4 5 4 0 4 0]\n",
      " [0 0 0 0 0 0]\n",
      " [2 2 3 0 3 0]]\n",
      "(1275288, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(content_list)\n",
    "\n",
    "ipc_Xdata = np.array(tokenizer.texts_to_sequences(content_list))\n",
    "\n",
    "print(ipc_Xdata)\n",
    "print(ipc_Xdata.shape)\n",
    "\n",
    "ipc_Ydata = np.array(raw_data[['Service', 'Cleanliness','Value',\n",
    "                               'Sleep Quality','Rooms','Location']])\n",
    "print(ipc_Ydata)\n",
    "print(ipc_Ydata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split & Get maxlen and max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T19:24:20.015230Z",
     "start_time": "2020-07-26T19:24:19.667860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(892701,) (382587,) (892701, 6) (382587, 6)\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(ipc_Xdata, ipc_Ydata, \n",
    "                                                    test_size=0.3)\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T13:40:34.518029Z",
     "start_time": "2020-07-27T13:40:23.166901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2654\n",
      "263169\n"
     ]
    }
   ],
   "source": [
    "# 최대 길이 및 최대 feature 값 구하기\n",
    "maxlen = 1\n",
    "max_features = 1\n",
    "for idx in ipc_Xdata :\n",
    "    try :\n",
    "        len_ = len(idx) #print(idx)\n",
    "        max_ = np.max(idx)\n",
    "    except :\n",
    "        #print(idx)\n",
    "        continue\n",
    "    #print(type(max_))\n",
    "    #break\n",
    "    if max_features < max_ :\n",
    "        max_features = max_\n",
    "    if maxlen < len_ :\n",
    "        maxlen = len_\n",
    "print(maxlen)\n",
    "print(max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T05:51:33.419252Z",
     "start_time": "2020-07-24T05:51:33.381734Z"
    }
   },
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T19:24:43.474895Z",
     "start_time": "2020-07-26T19:24:32.824914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "892701 train sequences\n",
      "382587 test sequences\n",
      "(892701,) (382587,) (892701, 6) (382587, 6)\n",
      "Pad sequences (samples x time)\n",
      "train_x shape: (892701, 2654)\n",
      "test_x shape: (382587, 2654)\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "\n",
    "print(len(train_x), 'train sequences')\n",
    "print(len(test_x), 'test sequences')\n",
    "\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "\n",
    "train_x = sequence.pad_sequences(train_x, maxlen=maxlen)\n",
    "test_x = sequence.pad_sequences(test_x, maxlen=maxlen)\n",
    "print('train_x shape:', train_x.shape)\n",
    "print('test_x shape:', test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### variables setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T19:24:43.602830Z",
     "start_time": "2020-07-26T19:24:43.600726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Embedding\n",
    "max_features = max_features+1 # feature 값 변경\n",
    "#maxlen = 2670 # 리뷰의 길이\n",
    "embedding_size = 128\n",
    "\n",
    "# Convolution\n",
    "kernel_size = 5 # 1\n",
    "filters = 128 # 256\n",
    "pool_size = 4\n",
    "\n",
    "# LSTM\n",
    "lstm_output_size = 10\n",
    "\n",
    "# Training\n",
    "batch_size = 3000 # 310 #30 -> 20\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T09:26:05.345571Z",
     "start_time": "2020-07-27T09:26:04.967320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 2654)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 2654, 256)    67371520    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2650, 128)    163968      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 662, 128)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 662, 128)     99328       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 662, 128)     0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 84736)        0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            84737       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            84737       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            84737       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            84737       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            84737       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            84737       flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 68,143,238\n",
      "Trainable params: 68,143,238\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "#model = Sequential()\n",
    "input_layer = layers.Input((maxlen,))\n",
    "\n",
    "embedding_layer = layers.Embedding(max_features, 256)(input_layer)\n",
    "\n",
    "convolution_layer = layers.Conv1D(128, 5, padding = 'valid',\n",
    "                                 activation='relu', strides=1)(embedding_layer)\n",
    "\n",
    "maxpooling_layer = layers.MaxPooling1D(pool_size)(convolution_layer)\n",
    "\n",
    "lstm_layer = layers.Bidirectional(layers.CuDNNLSTM(64,return_sequences=True))(maxpooling_layer)\n",
    "\n",
    "dropout_layer = layers.Dropout(0.25)(lstm_layer) \n",
    "\n",
    "flatten_layer = layers.Flatten()(dropout_layer)\n",
    "\n",
    "output_layer1 = layers.Dense(1, activation = 'sigmoid')(flatten_layer)\n",
    "output_layer2 = layers.Dense(1, activation = 'sigmoid')(flatten_layer)\n",
    "output_layer3 = layers.Dense(1, activation = 'sigmoid')(flatten_layer)\n",
    "output_layer4 = layers.Dense(1, activation = 'sigmoid')(flatten_layer)\n",
    "output_layer5 = layers.Dense(1, activation = 'sigmoid')(flatten_layer)\n",
    "output_layer6 = layers.Dense(1, activation = 'sigmoid')(flatten_layer)\n",
    "\n",
    "model = models.Model(inputs=input_layer, outputs=\n",
    "                     [output_layer1, output_layer2, output_layer3, output_layer4,\n",
    "                      output_layer5, output_layer6])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mse', optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-26T19:12:47.261Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 134743040 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    }
   ],
   "source": [
    "with K.tf.device('/gpu:0'):\n",
    "    print('Train...')\n",
    "    hist = model.fit(train_x, [train_y[:,0]/5, train_y[:,1]/5, \n",
    "                               train_y[:,2]/5, train_y[:,3]/5, \n",
    "                               train_y[:,4]/5, train_y[:,5]/5],\n",
    "                     batch_size=batch_size,\n",
    "                     epochs=epochs)\n",
    "    \n",
    "   # score, acc = model.evaluate(test_x, test_y[:,0:6], \n",
    "   #                             batch_size=batch_size)\n",
    "    \n",
    "    score = model.evaluate(test_x, [test_y[:,0]/5, test_y[:,1]/5,\n",
    "                                     test_y[:,2]/5, test_y[:,3]/5,\n",
    "                                     test_y[:,4]/5, test_y[:,5]/5], \n",
    "                            batch_size = batch_size)\n",
    "    \n",
    "    predicted = model.predict(test_x)\n",
    "    print('predicted : ',predicted)\n",
    "    #print('Test score:', score)\n",
    "    #print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T07:31:26.646405Z",
     "start_time": "2020-07-26T07:31:26.642936Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-57-85dbe6148206>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-57-85dbe6148206>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    arr = np.squeeze(arr_predicted, 2)\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(len(test_x))\n",
    "print(len(predicted))\n",
    "arr_predicted = np.array(predicted)\n",
    "print(arr_predicted.shape)\n",
    "print(arr_predicted)\n",
    "\n",
    "# 모델 변경사헝 확인하기\n",
    "\n",
    "arr = np.squeeze(arr_predicted, 2)\n",
    "arr = np.transpose(arr)\n",
    "print(arr.shape)\n",
    "print('times 5')\n",
    "# print(arr)\n",
    "arr = arr * 5\n",
    "arr = arr.astype('int64')\n",
    "print(arr.shape)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T18:57:57.033528Z",
     "start_time": "2020-07-25T18:57:57.030692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 3 1 1 5]\n",
      "[4 4 4 4 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(test_y[0])\n",
    "print(arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T18:57:59.578632Z",
     "start_time": "2020-07-25T18:57:59.575311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 1 3 1 1 5]\n",
      " [5 5 3 5 0 0]\n",
      " [5 4 4 4 5 5]\n",
      " [5 5 4 5 5 5]\n",
      " [5 5 5 0 5 3]]\n",
      "[[4 4 4 4 3 4]\n",
      " [3 3 3 2 2 3]\n",
      " [4 4 4 1 4 4]\n",
      " [4 4 3 2 3 3]\n",
      " [3 4 3 1 3 2]]\n"
     ]
    }
   ],
   "source": [
    "print(test_y[:5])\n",
    "print(arr[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning process graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T16:32:39.225237Z",
     "start_time": "2020-07-25T16:16:03.832Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "367.390625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1525px",
    "right": "20px",
    "top": "152px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
